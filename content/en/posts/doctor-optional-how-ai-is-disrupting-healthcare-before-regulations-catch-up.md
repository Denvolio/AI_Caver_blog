---
title: "Doctor? Optional. How AI Is Disrupting Healthcare..."
date: 2025-09-13
featuredImage: "/uploads/ai-doctor.png"
---
Doctor? Optional. How AI Is Disrupting Healthcare Before Regulations Catch Up

Denys Voroshylov

***

### ![](<media/static/uploads/ChatGPT Image 13 ÑĞµĞ½Ñ‚. 2025 Ğ³., 15_19_51.png>) Introduction: Three Diagnoses and One Algorithm

I live in Poland and, as a taxpayer, have access to the national health insurance system (NFZ). In emergency situations, it works well â€” if something is seriously wrong, you'll be saved, treated, hospitalized. But for "smaller" issues â€” recurring cystitis, ear inflammation, or a dependency on nasal sprays â€” things get tricky.

A free ENT appointment might be available in a month. A private one? Tomorrow, but itâ€™ll cost you â‚¬50. And here's the paradox: the outcome might be no better. The same doctor can be either an attentive expert or an indifferent technician, regardless of price. I opt for private care because I can at least speak English or Ukrainian. But even then, results aren't guaranteed.

Thatâ€™s why, in three specific instances, I turned not to a doctor â€” but to ChatGPT. And I got real results.

> Case 1. Rebound congestion after using nasal spray: ChatGPT identified the likely cause, suggested an over-the-counter alternative and a withdrawal plan. Three days later, I could breathe freely.
>
> Case 2. Suspected varicocele and cystitis: After an unhelpful urology visit (no tests, just Biseptol), I turned to ChatGPT. It recommended which tests to run, and suggested a plan involving herbal supplements and hygiene routines. Ten days later, the varicocele symptoms were gone and cystitis symptoms improved by 70%.

This isnâ€™t a confession. Itâ€™s a symptom â€” a systemic one.

***

### Why Are People Turning to AI for Health?

The answer is simple: weâ€™re tired of waiting. Tired of battling for basic tests. Tired of doctors rushing through diagnoses in under a minute. Tired of paying â€” and still feeling underserved.

This isnâ€™t just a Polish issue. A friend in Germany got an allergist appointmentâ€¦ for next year. In the UK? Even longer. In Spain, I used Google Translate to self-diagnose.

AI isnâ€™t a rebellion. Itâ€™s an alternative. Not perfect, but fast, accessible, and increasingly intelligent. And as The Rise of AI-Driven Self-Medication (2023â€“2025) report shows, Iâ€™m far from alone.

> â€œUsers are actively turning to ChatGPT, Claude, Gemini and other LLMs as a first line of consultation, especially in chronic, poorly diagnosed, or emotionally charged cases.â€ ([source](https://analyticsindiamag.com/global-tech/say-hi-to-doctor-chatgpt/))
![AI doctor booth](/uploads/ai-booth.png)
***

### What AI-Driven Self-Medication Looks Like

The study categorizes how laypeople are using AI for self-medication â€” and behind each category is a very human story.

#### ğŸ§  Self-Diagnosis

LLMs help users explore what might be causing their symptoms. One Reddit user, struggling with chronic back pain for over a decade, used ChatGPT to analyze the possible root causes, received a custom exercise plan â€” and within weeks, pain dropped by 60â€“70% ([source](https://www.reddit.com/r/unpopularopinion/comments/nmn6nd/self_diagnosing_is_okay/)).

#### ğŸ’¬ Mental Health Self-Screening

Reddit and similar platforms are full of stories about users using AI to explore ADHD, anxiety, depression. Sometimes itâ€™s a step toward real help. Sometimes, a dead end. But one thingâ€™s clear: people arenâ€™t just asking questions â€” theyâ€™re searching for frameworks to understand themselves better ([source](https://www.reddit.com/r/MentalHealthPH/comments/1aqgzkh/self_diagnosing/)).

#### ğŸ§¬ Personalized Health Plans

Perhaps the most remarkable case: a person with Type 1 Diabetes uploaded 110 biomarkers and 90 days of glucose data from a Dexcom sensor into ChatGPT. The AI returned a detailed plan for meals, supplements, workouts, and insulin adjustments. Their A1C dropped from 5.8 to 5.4 in six months ([source](https://www.reddit.com/r/diabetes_t1/comments/1iq0th5/i_used_chatgpt_to_get_my_health_together_and_it/)).

#### ğŸšª Skipping the Doctor

In many cases, itâ€™s not a choice â€” itâ€™s a reaction to disappointment. Delays, costs, dismissiveness. And hereâ€™s AI: always available, always responsive.

#### ğŸ¤– Emotional Support

AI is stepping into the role of unlicensed therapist. In Japan, adolescent cancer patients used GPT-powered chatbots for emotional support. 80% disclosed things to the chatbot that they hadnâ€™t told their families or doctors ([source](https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2025.1543543/full)).

***
![ChatGPT coffee session](/uploads/chatgpt-coffee.png)
### When AI Gets It Dangerously Wrong

AI isnâ€™t magic. It makes mistakes. And sometimes, theyâ€™re serious.

* The â€œTessaâ€ chatbot from the National Eating Disorders Association advised calorie counting and fat-fold measurements â€” the opposite of recovery best practices. After public outrage, it was taken offline ([source](https://en.wikipedia.org/wiki/National_Eating_Disorders_Association)).
* Microsoftâ€™s Copilot AI gave potentially harmful drug advice in 22% of queries about the 50 most prescribed medications. 39% of its answers contradicted scientific consensus ([source](https://www.techrepublic.com/article/copilot-ai-medical-advice-harm/)).
* In urology, ChatGPT gave incorrect or misleading advice in 40% of cases, often citing made-up sources or omitting critical context ([source](https://ufhealth.org/news/2023/uf-college-of-medicine-research-shows-ai-chatbot-flawed-when-giving-urology-advice)).

The problem isnâ€™t just that AI can be wrong. Itâ€™s that it can sound absolutely right while being completely wrong.

***

### AI as Healthcareâ€™s First Responder

And yet â€” AI is becoming our first line of defense. Itâ€™s always there. It doesnâ€™t get tired. It doesnâ€™t judge. It doesnâ€™t say â€œthatâ€™s not my department.â€

> â€œPatients often perceive AI as less judgmental, more explanatory, and more convenient when interacting with medical information.â€ ([source](https://readysetrecover.com/blog/using-ai-for-medical-advice))

Doctors donâ€™t always have time to explain. But AI does. And increasingly, it explains better.

***

### Where Demand Goes, Innovation Follows

The market is massive â€” and already breaking through old boundaries.

AI services are quietly embedding into:

* Insurance app features.
* Telemedicine interfaces.
* At-home biosensors (from wearables to mail-in blood tests).
* Grey-zone Telegram bots combining GPT with diagnostics and treatment protocols.

But this race has a weak leg: regulation.

* Insurance doesnâ€™t cover AI diagnostics.
* Legally, no oneâ€™s liable when AI gives bad advice.
* The FDA and EU regulators focus only on certified medical software â€” not on ChatGPT chatting on your phone ([source](https://www.fda.gov/science-research/science-and-research-special-topics/artificial-intelligence-and-medical-products)).

AI in medicine is like Uber in 2012 â€” already operating, but still technically â€œunrecognized.â€ Users donâ€™t wait. And neither do businesses.

***

### Donâ€™t Wait â€” Heal

AI isnâ€™t perfect. But it offers what many systems canâ€™t: attention, clarity, speed, personalization. We donâ€™t need to wait for the system to fix itself. Weâ€™re already healing.

Our job is to use these tools wisely, critically, and creatively. Donâ€™t follow blindly â€” but donâ€™t be afraid to explore.

And for businesses? The market is forming where traditional coverage is silent.

When fully autonomous GPT-9 diagnostic kiosks roll out in a decade, some of us will say: weâ€™ve been there. We healed. We just didnâ€™t wait.

> â€œAI isnâ€™t your doctor. But itâ€™s sitting right next to you as you decide whether to treat or delay. And often, it says something worth hearing. The key is to listen with wisdom â€” not instead of it.â€
