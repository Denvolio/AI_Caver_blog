---
title: "Doctor? Optional. How AI Is Disrupting Healthcare..."
date: 2025-09-13
slug: "doctor-optional"
featuredImage: "/uploads/ai-doctor.png"
translationKey: "doctor-optional"
draft: false
---
Doctor? Optional. How AI Is Disrupting Healthcare Before Regulations Catch Up

Denys Voroshylov

***

### ![](<media/static/uploads/ChatGPT Image 13 —Å–µ–Ω—Ç. 2025 –≥., 15_19_51.png>) Introduction: Three Diagnoses and One Algorithm

I live in Poland and, as a taxpayer, have access to the national health insurance system (NFZ). In emergency situations, it works well ‚Äî if something is seriously wrong, you'll be saved, treated, hospitalized. But for "smaller" issues ‚Äî recurring cystitis, ear inflammation, or a dependency on nasal sprays ‚Äî things get tricky.

A free ENT appointment might be available in a month. A private one? Tomorrow, but it‚Äôll cost you ‚Ç¨50. And here's the paradox: the outcome might be no better. The same doctor can be either an attentive expert or an indifferent technician, regardless of price. I opt for private care because I can at least speak English or Ukrainian. But even then, results aren't guaranteed.

That‚Äôs why, in three specific instances, I turned not to a doctor ‚Äî but to ChatGPT. And I got real results.

> Case 1. Rebound congestion after using nasal spray: ChatGPT identified the likely cause, suggested an over-the-counter alternative and a withdrawal plan. Three days later, I could breathe freely.
>
> Case 2. Suspected varicocele and cystitis: After an unhelpful urology visit (no tests, just Biseptol), I turned to ChatGPT. It recommended which tests to run, and suggested a plan involving herbal supplements and hygiene routines. Ten days later, the varicocele symptoms were gone and cystitis symptoms improved by 70%.

This isn‚Äôt a confession. It‚Äôs a symptom ‚Äî a systemic one.

***

### Why Are People Turning to AI for Health?

The answer is simple: we‚Äôre tired of waiting. Tired of battling for basic tests. Tired of doctors rushing through diagnoses in under a minute. Tired of paying ‚Äî and still feeling underserved.

This isn‚Äôt just a Polish issue. A friend in Germany got an allergist appointment‚Ä¶ for next year. In the UK? Even longer. In Spain, I used Google Translate to self-diagnose.

AI isn‚Äôt a rebellion. It‚Äôs an alternative. Not perfect, but fast, accessible, and increasingly intelligent. And as The Rise of AI-Driven Self-Medication (2023‚Äì2025) report shows, I‚Äôm far from alone.

> ‚ÄúUsers are actively turning to ChatGPT, Claude, Gemini and other LLMs as a first line of consultation, especially in chronic, poorly diagnosed, or emotionally charged cases.‚Äù ([source](https://analyticsindiamag.com/global-tech/say-hi-to-doctor-chatgpt/))
![AI doctor booth](/uploads/ai-booth.png)
***

### What AI-Driven Self-Medication Looks Like

The study categorizes how laypeople are using AI for self-medication ‚Äî and behind each category is a very human story.

#### üß† Self-Diagnosis

LLMs help users explore what might be causing their symptoms. One Reddit user, struggling with chronic back pain for over a decade, used ChatGPT to analyze the possible root causes, received a custom exercise plan ‚Äî and within weeks, pain dropped by 60‚Äì70% ([source](https://www.reddit.com/r/unpopularopinion/comments/nmn6nd/self_diagnosing_is_okay/)).

#### üí¨ Mental Health Self-Screening

Reddit and similar platforms are full of stories about users using AI to explore ADHD, anxiety, depression. Sometimes it‚Äôs a step toward real help. Sometimes, a dead end. But one thing‚Äôs clear: people aren‚Äôt just asking questions ‚Äî they‚Äôre searching for frameworks to understand themselves better ([source](https://www.reddit.com/r/MentalHealthPH/comments/1aqgzkh/self_diagnosing/)).

#### üß¨ Personalized Health Plans

Perhaps the most remarkable case: a person with Type 1 Diabetes uploaded 110 biomarkers and 90 days of glucose data from a Dexcom sensor into ChatGPT. The AI returned a detailed plan for meals, supplements, workouts, and insulin adjustments. Their A1C dropped from 5.8 to 5.4 in six months ([source](https://www.reddit.com/r/diabetes_t1/comments/1iq0th5/i_used_chatgpt_to_get_my_health_together_and_it/)).

#### üö™ Skipping the Doctor

In many cases, it‚Äôs not a choice ‚Äî it‚Äôs a reaction to disappointment. Delays, costs, dismissiveness. And here‚Äôs AI: always available, always responsive.

#### ü§ñ Emotional Support

AI is stepping into the role of unlicensed therapist. In Japan, adolescent cancer patients used GPT-powered chatbots for emotional support. 80% disclosed things to the chatbot that they hadn‚Äôt told their families or doctors ([source](https://www.frontiersin.org/journals/digital-health/articles/10.3389/fdgth.2025.1543543/full)).

***
![ChatGPT coffee session](/uploads/chatgpt-coffee.png)
### When AI Gets It Dangerously Wrong

AI isn‚Äôt magic. It makes mistakes. And sometimes, they‚Äôre serious.

* The ‚ÄúTessa‚Äù chatbot from the National Eating Disorders Association advised calorie counting and fat-fold measurements ‚Äî the opposite of recovery best practices. After public outrage, it was taken offline ([source](https://en.wikipedia.org/wiki/National_Eating_Disorders_Association)).
* Microsoft‚Äôs Copilot AI gave potentially harmful drug advice in 22% of queries about the 50 most prescribed medications. 39% of its answers contradicted scientific consensus ([source](https://www.techrepublic.com/article/copilot-ai-medical-advice-harm/)).
* In urology, ChatGPT gave incorrect or misleading advice in 40% of cases, often citing made-up sources or omitting critical context ([source](https://ufhealth.org/news/2023/uf-college-of-medicine-research-shows-ai-chatbot-flawed-when-giving-urology-advice)).

The problem isn‚Äôt just that AI can be wrong. It‚Äôs that it can sound absolutely right while being completely wrong.

***

### AI as Healthcare‚Äôs First Responder

And yet ‚Äî AI is becoming our first line of defense. It‚Äôs always there. It doesn‚Äôt get tired. It doesn‚Äôt judge. It doesn‚Äôt say ‚Äúthat‚Äôs not my department.‚Äù

> ‚ÄúPatients often perceive AI as less judgmental, more explanatory, and more convenient when interacting with medical information.‚Äù ([source](https://readysetrecover.com/blog/using-ai-for-medical-advice))

Doctors don‚Äôt always have time to explain. But AI does. And increasingly, it explains better.

***

### Where Demand Goes, Innovation Follows

The market is massive ‚Äî and already breaking through old boundaries.

AI services are quietly embedding into:

* Insurance app features.
* Telemedicine interfaces.
* At-home biosensors (from wearables to mail-in blood tests).
* Grey-zone Telegram bots combining GPT with diagnostics and treatment protocols.

But this race has a weak leg: regulation.

* Insurance doesn‚Äôt cover AI diagnostics.
* Legally, no one‚Äôs liable when AI gives bad advice.
* The FDA and EU regulators focus only on certified medical software ‚Äî not on ChatGPT chatting on your phone ([source](https://www.fda.gov/science-research/science-and-research-special-topics/artificial-intelligence-and-medical-products)).

AI in medicine is like Uber in 2012 ‚Äî already operating, but still technically ‚Äúunrecognized.‚Äù Users don‚Äôt wait. And neither do businesses.

***

### Don‚Äôt Wait ‚Äî Heal

AI isn‚Äôt perfect. But it offers what many systems can‚Äôt: attention, clarity, speed, personalization. We don‚Äôt need to wait for the system to fix itself. We‚Äôre already healing.

Our job is to use these tools wisely, critically, and creatively. Don‚Äôt follow blindly ‚Äî but don‚Äôt be afraid to explore.

And for businesses? The market is forming where traditional coverage is silent.

When fully autonomous GPT-9 diagnostic kiosks roll out in a decade, some of us will say: we‚Äôve been there. We healed. We just didn‚Äôt wait.

> ‚ÄúAI isn‚Äôt your doctor. But it‚Äôs sitting right next to you as you decide whether to treat or delay. And often, it says something worth hearing. The key is to listen with wisdom ‚Äî not instead of it.‚Äù
